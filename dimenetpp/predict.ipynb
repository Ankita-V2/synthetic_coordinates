{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import string\n",
    "import random\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dimenet.model.dimenet_pp import DimeNetPP\n",
    "from dimenet.model.activations import swish\n",
    "from dimenet.training.trainer import Trainer\n",
    "from dimenet.training.metrics import Metrics\n",
    "from dimenet.training.data_container import DataContainer\n",
    "from dimenet.training.data_provider import DataProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger\n",
    "logger = logging.getLogger()\n",
    "logger.handlers = []\n",
    "ch = logging.StreamHandler()\n",
    "formatter = logging.Formatter(\n",
    "        fmt='%(asctime)s (%(levelname)s): %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "logger.setLevel('INFO')\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "tf.get_logger().setLevel('WARN')\n",
    "tf.autograph.set_verbosity(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use ablation: const_angle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 55/10000 [00:00<00:18, 542.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing molecules\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 601/10000 [00:01<00:17, 533.60it/s]RDKit ERROR: [15:27:35] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      " 18%|█▊        | 1795/10000 [00:03<00:15, 531.41it/s]RDKit ERROR: [15:27:38] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      " 25%|██▌       | 2505/10000 [00:04<00:13, 536.18it/s]RDKit ERROR: [15:27:39] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      " 33%|███▎      | 3270/10000 [00:06<00:12, 537.16it/s]RDKit ERROR: [15:27:40] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      " 90%|████████▉ | 8979/10000 [00:16<00:01, 534.38it/s]RDKit ERROR: [15:27:51] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      " 90%|█████████ | 9033/10000 [00:16<00:01, 535.63it/s]RDKit ERROR: [15:27:51] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "100%|██████████| 10000/10000 [00:18<00:00, 535.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped: 6\n"
     ]
    }
   ],
   "source": [
    "# config.yaml for DimeNet, config_pp.yaml for DimeNet++\n",
    "with open('config_pp.yaml', 'r') as c:\n",
    "    config = yaml.safe_load(c)\n",
    "    \n",
    "model_name = config['model_name']\n",
    "\n",
    "if model_name == \"dimenet\":\n",
    "    num_bilinear = config['num_bilinear']\n",
    "elif model_name == \"dimenet++\":\n",
    "    out_emb_size = config['out_emb_size']\n",
    "    int_emb_size = config['int_emb_size']\n",
    "    basis_emb_size = config['basis_emb_size']\n",
    "else:\n",
    "    raise ValueError(f\"Unknown model name: '{model_name}'\")\n",
    "    \n",
    "emb_size = config['emb_size']\n",
    "num_blocks = config['num_blocks']\n",
    "\n",
    "num_spherical = config['num_spherical']\n",
    "num_radial = config['num_radial']\n",
    "output_init = config['output_init']\n",
    "\n",
    "cutoff = config['cutoff']\n",
    "\n",
    "num_before_skip = config['num_before_skip']\n",
    "num_after_skip = config['num_after_skip']\n",
    "num_dense_output = config['num_dense_output']\n",
    "\n",
    "num_train = config['num_train']\n",
    "num_valid = config['num_valid']\n",
    "data_seed = config['data_seed']\n",
    "dataset_path = config['dataset']\n",
    "\n",
    "batch_size = config['batch_size']\n",
    "\n",
    "dist = config['dist']\n",
    "ablation = config['ablation']\n",
    "\n",
    "#####################################################################\n",
    "# Change this if you want to predict a different target, e.g. to ['U0']\n",
    "# (but don't forget to change output_init as well)\n",
    "targets = config['targets']\n",
    "#####################################################################\n",
    "\n",
    "############### load dataset\n",
    "data_container = DataContainer(dataset_path + \"/test.jsonl.gz\", target_keys=targets, dist=dist, subset=False, ablation=ablation)\n",
    "\n",
    "# Initialize DataProvider (splits dataset into training, validation and test set based on data_seed)\n",
    "data_provider = DataProvider({'test': data_container}, num_train, num_valid, batch_size,\n",
    "                             seed=data_seed, dist=dist)\n",
    "\n",
    "# Initialize datasets\n",
    "dataset = data_provider.get_dataset('test').prefetch(tf.data.experimental.AUTOTUNE)\n",
    "dataset_iter = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "if model_name == \"dimenet++\":\n",
    "    model = DimeNetPP(\n",
    "            emb_size=emb_size, out_emb_size=out_emb_size,\n",
    "            int_emb_size=int_emb_size, basis_emb_size=basis_emb_size,\n",
    "            num_blocks=num_blocks, num_spherical=num_spherical, num_radial=num_radial,\n",
    "            cutoff=cutoff, num_before_skip=num_before_skip, num_after_skip=num_after_skip,\n",
    "            num_dense_output=num_dense_output, num_targets=len(targets),\n",
    "            activation=swish, output_init=output_init, dist=dist)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown model name: '{model_name}'\")\n",
    "    \n",
    "trainer = Trainer(model)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f191df404d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################################\n",
    "# Load the trained model from your own training run\n",
    "directory = \"logs/20210518_141556_qxRCa89m_qm9_e128_oe256_ie64_be8_sbf12_rbf12_b4_nbs1_nas2_no3_cut2.5_lr1.00e-03_dec4.00e+06_U0_DimeNet++\"\n",
    "best_ckpt_file = os.path.join(directory, 'best', 'ckpt')\n",
    "#####################################################################\n",
    "# Uncomment this if you want to use a pretrained model\n",
    "# directory = f\"pretrained/dimenet_pp/{targets[0]}\"\n",
    "# best_ckpt_file = os.path.join(directory, 'ckpt')\n",
    "#####################################################################\n",
    "\n",
    "model.load_weights(best_ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:11<00:00, 27.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize aggregates\n",
    "metrics = Metrics('val', targets)\n",
    "preds_total = np.zeros([data_provider.nsamples['test'], len(targets)], dtype=np.float32)\n",
    "\n",
    "steps_per_epoch = int(np.ceil(data_provider.nsamples['test'] / batch_size))\n",
    "\n",
    "for step in tqdm(range(steps_per_epoch)):\n",
    "    preds = trainer.predict_on_batch(dataset_iter, metrics)\n",
    "    \n",
    "    # Update predictions\n",
    "    batch_start = step * batch_size\n",
    "    batch_end = min((step + 1) * batch_size, data_provider.nsamples['test'])\n",
    "    preds_total[batch_start:batch_end] = preds.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U0 MAE: 0.032134927809238434\n",
      "U0 logMAE: -3.437811851501465\n"
     ]
    }
   ],
   "source": [
    "print(f\"{','.join(targets)} MAE: {metrics.mean_mae}\")\n",
    "print(f\"{','.join(targets)} logMAE: {metrics.mean_log_mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
